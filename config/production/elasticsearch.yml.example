index:
  number_of_shards: 1
  number_of_replicas: 0  # not for production

  analysis:
    char_filter:
      ru:
        type: mapping
        mappings: ['Ё=>Е', 'ё=>е']
    analyzer:
      default:
        type: custom
        tokenizer: standard
        filter: [custom_word_delimiter, lowercase, russian_morphology, english_morphology, stopwords_ru, stop]
        char_filter: [ru]
    filter:
      stopwords_ru:
        type: stop
        stopwords: [а,без,более,бы,был,была,были,было,быть,в,вам,вас,весь,во,вот,все,всего,всех,вы,где,да,даже,для,до,его,ее,если,есть,еще,же,за,здесь,и,из,или,им,их,к,как,ко,когда,кто,ли,либо,мне,может,мы,на,надо,наш,не,него,нее,нет,ни,них,но,ну,о,об,однако,он,она,они,оно,от,очень,по,под,при,с,со,так,также,такой,там,те,тем,то,того,тоже,той,только,том,ты,у,уже,хотя,чего,чей,чем,что,чтобы,чье,чья,эта,эти,это,я]
        ignore_case: true
      custom_word_delimiter:
        type: word_delimiter
        # "PowerShot" ⇒ "Power" "Shot", части одного слова становятся отдельными токенами
        generate_word_parts: true
        generate_number_parts: true  # "500-42" ⇒ "500" "42"
        catenate_words: false  # "wi-fi" ⇒ "wifi"
        catenate_numbers: false  # "500-42" ⇒ "50042"
        catenate_all: false  # "wi-fi-4000" ⇒ "wifi4000"
        split_on_case_change: true  # "PowerShot" ⇒ "Power" "Shot"
        preserve_original: false  # "500-42" ⇒ "500-42" "500" "42"
        split_on_numerics: true  # "j2se" ⇒ "j" "2" "se"
